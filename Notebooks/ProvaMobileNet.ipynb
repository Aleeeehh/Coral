{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41bad252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento modello MobileNet V2...\n",
      "Modello caricato: <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n",
      "Conversione in TFLite...\n",
      "Modello convertito e salvato: mobilenet_v2_float32.tflite\n",
      "Dimensione modello: 6.4 MB\n",
      "\n",
      "Test del modello convertito...\n",
      "Input shape: [  1 128 128   3]\n",
      "Input type: <class 'numpy.float32'>\n",
      "Output shape: [   1 1001]\n",
      "Output type: <class 'numpy.float32'>\n",
      "✅ Conversione completata con successo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1753449538.804674 4399149 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1753449538.805375 4399149 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-07-25 15:18:58.809545: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: mobilenetV2\n",
      "2025-07-25 15:18:58.817164: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-07-25 15:18:58.817185: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: mobilenetV2\n",
      "I0000 00:00:1753449538.875815 4399149 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-07-25 15:18:58.886812: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-07-25 15:18:59.297279: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: mobilenetV2\n",
      "2025-07-25 15:18:59.396519: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 587311 microseconds.\n",
      "2025-07-25 15:18:59.527943: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "/Users/alessioprato/Desktop/Tesi Nuova/ESP32CAM_ESPIDF/.venv/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Percorso del modello scaricato\n",
    "model_path = \"mobilenetV2\"\n",
    "\n",
    "# Carica il modello SavedModel\n",
    "print(\"Caricamento modello MobileNet V2...\")\n",
    "model = tf.saved_model.load(model_path)\n",
    "\n",
    "# Verifica che il modello sia caricato correttamente\n",
    "print(f\"Modello caricato: {type(model)}\")\n",
    "\n",
    "# Converti in TensorFlow Lite\n",
    "print(\"Conversione in TFLite...\")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "\n",
    "# Configura le opzioni di conversione per ottimizzare per ESP32\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "# Converti il modello\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Salva il modello TFLite\n",
    "output_path = \"mobilenet_v2_float32.tflite\"\n",
    "with open(output_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Modello convertito e salvato: {output_path}\")\n",
    "print(f\"Dimensione modello: {len(tflite_model) / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Test del modello convertito\n",
    "print(\"\\nTest del modello convertito...\")\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Ottieni informazioni sui tensori di input/output\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Input shape: {input_details[0]['shape']}\")\n",
    "print(f\"Input type: {input_details[0]['dtype']}\")\n",
    "print(f\"Output shape: {output_details[0]['shape']}\")\n",
    "print(f\"Output type: {output_details[0]['dtype']}\")\n",
    "\n",
    "print(\"✅ Conversione completata con successo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESP32CAM Python (venv)",
   "language": "python",
   "name": "esp32cam_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
