{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312270ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formato dell'input del modello: <class 'numpy.float32'>\n",
      "formato output del modello: <class 'numpy.float32'>\n",
      "Shape output: (1, 84, 8400)\n",
      "predictions shape: (8400, 84)\n",
      "prima riga: [5.40647328e-01 1.51085123e-01 8.51498842e-02 4.00711894e-02\n",
      " 2.79087430e-07 6.26703880e-08 3.29604177e-07 6.01762480e-08\n",
      " 1.32663345e-07 7.62738921e-08 7.28267437e-08 6.29471231e-08\n",
      " 1.61372540e-07 6.91916711e-08 1.55344235e-08 6.17176070e-08\n",
      " 2.56964405e-08 1.74080597e-07 2.06534068e-07 6.85886832e-08\n",
      " 5.10500868e-08 7.56553575e-08 5.57399922e-08 8.17181132e-08\n",
      " 1.03012141e-07 6.16727718e-08 7.68923556e-08 7.43975193e-08\n",
      " 1.57854444e-07 3.22302526e-07 1.44844464e-07 1.74556220e-07\n",
      " 7.69884778e-08 1.58081775e-07 2.65187907e-07 9.33271380e-08\n",
      " 7.09081931e-08 1.48563984e-07 2.10989526e-07 4.97726766e-08\n",
      " 6.40138040e-08 2.40848721e-07 8.98006363e-08 4.40786572e-08\n",
      " 3.20233156e-08 6.13186657e-08 2.64282818e-07 2.86992559e-07\n",
      " 2.62695181e-07 1.63428197e-07 2.01161612e-07 1.06888720e-07\n",
      " 4.81617128e-08 8.73457680e-08 1.11337435e-07 2.39794446e-07\n",
      " 7.81161944e-08 6.61470594e-08 8.17549051e-08 7.24121847e-08\n",
      " 1.51358989e-07 4.54889673e-08 5.69330005e-08 7.92622430e-08\n",
      " 2.11714948e-07 6.67559377e-08 8.53935518e-08 7.68318031e-08\n",
      " 4.56273064e-08 8.79063293e-08 6.90768189e-08 1.64994077e-07\n",
      " 6.12792590e-08 6.34309032e-08 3.76398184e-08 1.75574144e-07\n",
      " 5.98577827e-08 2.10300286e-07 1.16186612e-07 2.98171479e-08\n",
      " 2.19675570e-07 5.79960222e-08 7.68867849e-08 1.61344218e-07]\n"
     ]
    }
   ],
   "source": [
    "# Esperimenti sull'output di inferenza a mano\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "nomeModello = \"Modelli/Utili/yolo11n_float32.tflite\"\n",
    "nomeImmagine = \"Foto/example4_preprocessed.jpg\"\n",
    "\n",
    "#converte l'immagine in RGB\n",
    "img = Image.open(nomeImmagine).convert('RGB')\n",
    "\n",
    "# Converti in un tensore 3d con valori float32 e normalizza (valori da 0 a 1)\n",
    "input_data =  np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "#aggiungi dimensione batch (1, 640, 640, 3) (Yolo si aspetta sempre un batch di input)\n",
    "#YOLO richiede input di forma (batch_size, height, width, channels) (ottenendo un tensore 4d)\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "#carica il modello\n",
    "interpreter = tf.lite.Interpreter(model_path=nomeModello)\n",
    "interpreter.allocate_tensors() #alloca memoria per i tensori\n",
    "\n",
    "#formati input/output modello\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"formato dell'input del modello:\", input_details[0]['dtype'])\n",
    "print(\"formato output del modello:\", output_details[0]['dtype'])\n",
    "\n",
    "# --- Imposta tensore input ---\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data) \n",
    "\n",
    "# --- Esegui inferenza ---\n",
    "interpreter.invoke()\n",
    "\n",
    "# --- Ottieni output ---\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "predictions = output_data[0]\n",
    "\n",
    "# --- Analisi output ---\n",
    "print(\"Shape output:\", output_data.shape)\n",
    "predictions = predictions.T #faccio la trasposta per avere su ogni riga una predizione\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "#print(\"predictions:\", predictions)\n",
    "print(\"prima riga:\", predictions[1002])\n",
    "\n",
    "objectness = predictions[:, 4]\n",
    "class_0_probs = predictions[:, 5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47592567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usiamo la libreria ultralytics per fare inferenza con YOLO11n\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\") #esporta in .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c93bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n",
      "Input shape: [1, 3, 640, 640]\n"
     ]
    }
   ],
   "source": [
    "#verifica dimensione input del modello\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"yolov8n.onnx\")\n",
    "for input in model.graph.input:\n",
    "    print(input.name)\n",
    "    shape = [dim.dim_value for dim in input.type.tensor_type.shape.dim]\n",
    "    print(\"Input shape:\", shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"onnx\") #esporta in .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d81fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and save results with Ultralytics\n",
    "nomeImmagine = \"../../Calibrazione/immagini_calibrazione640x480/capture(1).jpg\"\n",
    "results = model.predict(\n",
    "    nomeImmagine, \n",
    "    save=True, \n",
    "    project=\"../../FotoInference\",\n",
    "    name=\"detection\",\n",
    ")\n",
    "print(\"results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de977a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantizzazione del modello che non funziona\n",
    "import sys, os\n",
    "import esp_ppq\n",
    "#sys.path.append(os.path.abspath(\"esp-detection\"))\n",
    "from deploy.quantize import quant_espdet\n",
    "\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "quant_espdet(\n",
    "    onnx_path=\"yolo11n.onnx\",      # onnx appena esportato\n",
    "    target=\"esp32s3\",              \n",
    "    num_of_bits=8,                 # quantizzazione int8\n",
    "    device='cpu',\n",
    "    batchsz=1,\n",
    "    imgsz=[640, 640],              # deve combaciare con la dimensione del modello\n",
    "    calib_dir=\"../../Calibrazione/immagini_ridimensionate640x640/\",        #  cartella immagini reali\n",
    "    espdl_model_path=\"yolo11n.espdl\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewNotebooks2",
   "language": "python",
   "name": "esp32cam_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
