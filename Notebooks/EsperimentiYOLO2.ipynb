{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312270ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formato dell'input del modello: <class 'numpy.float32'>\n",
      "formato output del modello: <class 'numpy.float32'>\n",
      "Shape output: (1, 84, 8400)\n",
      "predictions shape: (8400, 84)\n",
      "prima riga: [5.40647328e-01 1.51085123e-01 8.51498842e-02 4.00711894e-02\n",
      " 2.79087430e-07 6.26703880e-08 3.29604177e-07 6.01762480e-08\n",
      " 1.32663345e-07 7.62738921e-08 7.28267437e-08 6.29471231e-08\n",
      " 1.61372540e-07 6.91916711e-08 1.55344235e-08 6.17176070e-08\n",
      " 2.56964405e-08 1.74080597e-07 2.06534068e-07 6.85886832e-08\n",
      " 5.10500868e-08 7.56553575e-08 5.57399922e-08 8.17181132e-08\n",
      " 1.03012141e-07 6.16727718e-08 7.68923556e-08 7.43975193e-08\n",
      " 1.57854444e-07 3.22302526e-07 1.44844464e-07 1.74556220e-07\n",
      " 7.69884778e-08 1.58081775e-07 2.65187907e-07 9.33271380e-08\n",
      " 7.09081931e-08 1.48563984e-07 2.10989526e-07 4.97726766e-08\n",
      " 6.40138040e-08 2.40848721e-07 8.98006363e-08 4.40786572e-08\n",
      " 3.20233156e-08 6.13186657e-08 2.64282818e-07 2.86992559e-07\n",
      " 2.62695181e-07 1.63428197e-07 2.01161612e-07 1.06888720e-07\n",
      " 4.81617128e-08 8.73457680e-08 1.11337435e-07 2.39794446e-07\n",
      " 7.81161944e-08 6.61470594e-08 8.17549051e-08 7.24121847e-08\n",
      " 1.51358989e-07 4.54889673e-08 5.69330005e-08 7.92622430e-08\n",
      " 2.11714948e-07 6.67559377e-08 8.53935518e-08 7.68318031e-08\n",
      " 4.56273064e-08 8.79063293e-08 6.90768189e-08 1.64994077e-07\n",
      " 6.12792590e-08 6.34309032e-08 3.76398184e-08 1.75574144e-07\n",
      " 5.98577827e-08 2.10300286e-07 1.16186612e-07 2.98171479e-08\n",
      " 2.19675570e-07 5.79960222e-08 7.68867849e-08 1.61344218e-07]\n"
     ]
    }
   ],
   "source": [
    "# Esperimenti sull'output di inferenza a mano\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "nomeModello = \"Modelli/Utili/yolo11n_float32.tflite\"\n",
    "nomeImmagine = \"Foto/example4_preprocessed.jpg\"\n",
    "\n",
    "#converte l'immagine in RGB\n",
    "img = Image.open(nomeImmagine).convert('RGB')\n",
    "\n",
    "# Converti in un tensore 3d con valori float32 e normalizza (valori da 0 a 1)\n",
    "input_data =  np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "#aggiungi dimensione batch (1, 640, 640, 3) (Yolo si aspetta sempre un batch di input)\n",
    "#YOLO richiede input di forma (batch_size, height, width, channels) (ottenendo un tensore 4d)\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "#carica il modello\n",
    "interpreter = tf.lite.Interpreter(model_path=nomeModello)\n",
    "interpreter.allocate_tensors() #alloca memoria per i tensori\n",
    "\n",
    "#formati input/output modello\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"formato dell'input del modello:\", input_details[0]['dtype'])\n",
    "print(\"formato output del modello:\", output_details[0]['dtype'])\n",
    "\n",
    "# --- Imposta tensore input ---\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data) \n",
    "\n",
    "# --- Esegui inferenza ---\n",
    "interpreter.invoke()\n",
    "\n",
    "# --- Ottieni output ---\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "predictions = output_data[0]\n",
    "\n",
    "# --- Analisi output ---\n",
    "print(\"Shape output:\", output_data.shape)\n",
    "predictions = predictions.T #faccio la trasposta per avere su ogni riga una predizione\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "#print(\"predictions:\", predictions)\n",
    "print(\"prima riga:\", predictions[1002])\n",
    "\n",
    "objectness = predictions[:, 4]\n",
    "class_0_probs = predictions[:, 5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47592567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:00<00:00, 28.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Usiamo la libreria ultralytics per fare inferenza con YOLO11n\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load an official model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d81fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/alessioprato/Desktop/Tesi Nuova/ESP32CAM_ESPIDF/Notebooks/../../Foto/example.jpg: 480x640 1 person, 1 clock, 91.2ms\n",
      "Speed: 3.5ms preprocess, 91.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1m../../FotoInference/detection\u001b[0m\n",
      "results: [ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[149, 159, 143],\n",
      "        [148, 158, 142],\n",
      "        [148, 158, 142],\n",
      "        ...,\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167]],\n",
      "\n",
      "       [[152, 162, 146],\n",
      "        [152, 162, 146],\n",
      "        [152, 162, 146],\n",
      "        ...,\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167]],\n",
      "\n",
      "       [[159, 166, 151],\n",
      "        [159, 166, 151],\n",
      "        [158, 165, 150],\n",
      "        ...,\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167],\n",
      "        [177, 182, 167]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 77,  92, 125],\n",
      "        [ 77,  92, 125],\n",
      "        [ 76,  93, 126],\n",
      "        ...,\n",
      "        [ 41,  57,  56],\n",
      "        [ 41,  57,  56],\n",
      "        [ 41,  57,  56]],\n",
      "\n",
      "       [[ 77,  92, 125],\n",
      "        [ 78,  93, 126],\n",
      "        [ 76,  93, 126],\n",
      "        ...,\n",
      "        [ 40,  56,  55],\n",
      "        [ 40,  56,  55],\n",
      "        [ 41,  57,  56]],\n",
      "\n",
      "       [[ 78,  93, 126],\n",
      "        [ 78,  93, 126],\n",
      "        [ 77,  94, 127],\n",
      "        ...,\n",
      "        [ 38,  56,  55],\n",
      "        [ 38,  56,  55],\n",
      "        [ 38,  56,  55]]], shape=(480, 640, 3), dtype=uint8)\n",
      "orig_shape: (480, 640)\n",
      "path: '/Users/alessioprato/Desktop/Tesi Nuova/ESP32CAM_ESPIDF/Notebooks/../../Foto/example.jpg'\n",
      "probs: None\n",
      "save_dir: '../../FotoInference/detection'\n",
      "speed: {'preprocess': 3.494375036098063, 'inference': 91.1882920190692, 'postprocess': 5.1520419656299055}]\n"
     ]
    }
   ],
   "source": [
    "# Predict with the model\n",
    "nomeImmagine = \"../../Foto/example.jpg\"\n",
    "results = model.predict(\n",
    "    nomeImmagine, \n",
    "    save=True, \n",
    "    project=\"../../FotoInference\",\n",
    "    name=\"detection\",\n",
    ")\n",
    "print(\"results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewNotebooks",
   "language": "python",
   "name": "esp32cam_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
